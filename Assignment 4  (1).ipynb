{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxLpAw8jd4hv"
   },
   "source": [
    "## **Dataset Overview: Breast Cancer Dataset (from sklearn)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFf1JGSv7mSp"
   },
   "source": [
    "The **Breast Cancer** dataset is a well-known dataset available in the sklearn library, primarily used for classification tasks. The dataset contains information about various features of cell nuclei from breast cancer biopsies, with the goal of predicting whether the tumor is **malignant** (cancerous) or **benign** (non-cancerous).\n",
    "\n",
    "The dataset contains 30 features, derived from digital images of fine needle aspirate (FNA) of breast cancer tumors. These features represent various measurements related to the shape and texture of the cell nuclei."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Uin_Ucjd-W4"
   },
   "source": [
    "## **Data Acquisition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mVNu1HfAcfG5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "# Create the DataFrame from the data and feature names\n",
    "data_frame = pd.DataFrame(cancer_data['data'], columns=cancer_data['feature_names'])\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "data_frame.loc[:, 'target'] = cancer_data.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "850EbuMSgOPZ",
    "outputId": "fb0849f6-530a-470f-c15a-a99ed167abd1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows of the dataset\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnvAYs3EeGsr"
   },
   "source": [
    "## **Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8C0ionWac6CG",
    "outputId": "f71c3273-d219-497f-9a15-8ce1d3232524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      " 30  target                   569 non-null    int32  \n",
      "dtypes: float64(30), int32(1)\n",
      "memory usage: 135.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display basic information\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ASGAYx5c_P3",
    "outputId": "4b54fdea-dcc6-49d9-f9c2-4e3fe864a21b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value count in each column:\n",
      " mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "target                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(f\"Missing value count in each column:\\n {df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbvrO9Q-dI79",
    "outputId": "95f14df3-e988-4044-c50d-f18da58b6510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows : 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(f\"Duplicate rows : {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VVdc-wydLxv",
    "outputId": "4ce692ab-43ba-42b8-a383-57e09135d6ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics:\n",
      "\n",
      "       mean radius  mean texture  mean perimeter    mean area  \\\n",
      "count   569.000000    569.000000      569.000000   569.000000   \n",
      "mean     14.127292     19.289649       91.969033   654.889104   \n",
      "std       3.524049      4.301036       24.298981   351.914129   \n",
      "min       6.981000      9.710000       43.790000   143.500000   \n",
      "25%      11.700000     16.170000       75.170000   420.300000   \n",
      "50%      13.370000     18.840000       86.240000   551.100000   \n",
      "75%      15.780000     21.800000      104.100000   782.700000   \n",
      "max      28.110000     39.280000      188.500000  2501.000000   \n",
      "\n",
      "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
      "count       569.000000        569.000000      569.000000           569.000000   \n",
      "mean          0.096360          0.104341        0.088799             0.048919   \n",
      "std           0.014064          0.052813        0.079720             0.038803   \n",
      "min           0.052630          0.019380        0.000000             0.000000   \n",
      "25%           0.086370          0.064920        0.029560             0.020310   \n",
      "50%           0.095870          0.092630        0.061540             0.033500   \n",
      "75%           0.105300          0.130400        0.130700             0.074000   \n",
      "max           0.163400          0.345400        0.426800             0.201200   \n",
      "\n",
      "       mean symmetry  mean fractal dimension  ...  worst texture  \\\n",
      "count     569.000000              569.000000  ...     569.000000   \n",
      "mean        0.181162                0.062798  ...      25.677223   \n",
      "std         0.027414                0.007060  ...       6.146258   \n",
      "min         0.106000                0.049960  ...      12.020000   \n",
      "25%         0.161900                0.057700  ...      21.080000   \n",
      "50%         0.179200                0.061540  ...      25.410000   \n",
      "75%         0.195700                0.066120  ...      29.720000   \n",
      "max         0.304000                0.097440  ...      49.540000   \n",
      "\n",
      "       worst perimeter   worst area  worst smoothness  worst compactness  \\\n",
      "count       569.000000   569.000000        569.000000         569.000000   \n",
      "mean        107.261213   880.583128          0.132369           0.254265   \n",
      "std          33.602542   569.356993          0.022832           0.157336   \n",
      "min          50.410000   185.200000          0.071170           0.027290   \n",
      "25%          84.110000   515.300000          0.116600           0.147200   \n",
      "50%          97.660000   686.500000          0.131300           0.211900   \n",
      "75%         125.400000  1084.000000          0.146000           0.339100   \n",
      "max         251.200000  4254.000000          0.222600           1.058000   \n",
      "\n",
      "       worst concavity  worst concave points  worst symmetry  \\\n",
      "count       569.000000            569.000000      569.000000   \n",
      "mean          0.272188              0.114606        0.290076   \n",
      "std           0.208624              0.065732        0.061867   \n",
      "min           0.000000              0.000000        0.156500   \n",
      "25%           0.114500              0.064930        0.250400   \n",
      "50%           0.226700              0.099930        0.282200   \n",
      "75%           0.382900              0.161400        0.317900   \n",
      "max           1.252000              0.291000        0.663800   \n",
      "\n",
      "       worst fractal dimension      target  \n",
      "count               569.000000  569.000000  \n",
      "mean                  0.083946    0.627417  \n",
      "std                   0.018061    0.483918  \n",
      "min                   0.055040    0.000000  \n",
      "25%                   0.071460    0.000000  \n",
      "50%                   0.080040    1.000000  \n",
      "75%                   0.092080    1.000000  \n",
      "max                   0.207500    1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Basic statistics of the dataset\n",
    "print(\"Descriptive Statistics:\\n\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V277__odBKPK"
   },
   "source": [
    "**Observation :** This dataset's datatypes are correct, doesn't have missing values and no duplicate rows, hence dataset is cleaned and we can move to data preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XIQ7M4SPdONf"
   },
   "outputs": [],
   "source": [
    "# Separate features (X) from the target variable (y)\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo73mQNkePV2"
   },
   "source": [
    "## **Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EA7p5Npmdxuv",
    "outputId": "59c2ddd5-68d0-467e-abb9-7c21a7db1ddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 10 Features:\n",
      "\n",
      "Index(['mean perimeter', 'mean area', 'mean concavity', 'mean concave points',\n",
      "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
      "       'worst concavity', 'worst concave points'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Perform feature selection using RFE with a RandomForest classifier as the estimator\n",
    "estimator = RandomForestClassifier(random_state=42)\n",
    "rfe = RFE(estimator=estimator, n_features_to_select=10)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# Get and display the names of the top 10 selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Best 10 Features:\\n\")\n",
    "print(selected_features)\n",
    "\n",
    "# Filter the dataset to keep only the selected features\n",
    "X_selected = X[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xo1ZfawCeM1m"
   },
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "oPIPL3RtdpKM"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Use train_test_split to separate features and target into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler for feature scaling\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and apply the transformation to both training and test data\n",
    "X_train_scaled, X_test_scaled = scaler.fit(X_train), scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9aU7O_aiM0B"
   },
   "source": [
    "## **ANN Model Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dN_eK7O9gI0H",
    "outputId": "39c5f920-0d82-4057-97d6-338b6005ea8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Model Performance Evaluation:\n",
      "\n",
      "Accuracy: 0.9736842105263158\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create and configure the Artificial Neural Network (ANN)\n",
    "ann = MLPClassifier(random_state=42, max_iter=1000)\n",
    "\n",
    "# Fit the model on the training data\n",
    "ann.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = ann.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model's performance using accuracy and classification report\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "class_report = classification_report(y_test, predictions)\n",
    "\n",
    "# Output the results\n",
    "print(\"ANN Model Performance Evaluation:\\n\")\n",
    "print(f\"Accuracy: {accuracy}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynwO2UPGiXfK"
   },
   "source": [
    "## **Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Model Performance Summary:\n",
      "Accuracy: 0.9736842105263158\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the MLPClassifier with required parameters\n",
    "model = MLPClassifier(random_state=42, max_iter=1000)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Generate predictions on the test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy and generate classification report\n",
    "results = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'classification_report': classification_report(y_test, y_pred)\n",
    "}\n",
    "\n",
    "# Print out the evaluation results\n",
    "print(\"ANN Model Performance Summary:\")\n",
    "print(f\"Accuracy: {results['accuracy']}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(results['classification_report'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wuYC3h7ZtlbC",
    "outputId": "4d1db57e-c387-4f5f-b90a-5d6e82f46093"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters from GridSearchCV:\n",
      "\n",
      "{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (50,), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "Best Cross-validation Score: 0.9384615384615385\n",
      "\n",
      "Evaluation of the Best Model:\n",
      "\n",
      "Accuracy: 0.9649122807017544\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        43\n",
      "           1       0.99      0.96      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.97      0.96       114\n",
      "weighted avg       0.97      0.96      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define hyperparameter search space for the ANN model\n",
    "hyperparameters = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (150,), (200,)],  # Neurons in hidden layer\n",
    "    'activation': ['tanh', 'relu'],  # Activation functions\n",
    "    'solver': ['adam', 'sgd'],  # Optimization algorithms\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],  # Regularization\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive']  # Learning rate options\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with MLPClassifier and hyperparameter grid\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=MLPClassifier(max_iter=500, early_stopping=True, random_state=42),\n",
    "    param_grid=hyperparameters,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model using GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Display the best parameters and best score found\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Hyperparameters from GridSearchCV:\\n\")\n",
    "print(best_params)\n",
    "print(f\"Best Cross-validation Score: {best_score}\\n\")\n",
    "\n",
    "# Evaluate the best model from GridSearchCV on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "test_predictions = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Evaluation of the Best Model:\\n\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, test_predictions)}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, test_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElqyVb16A07m"
   },
   "source": [
    "## Model Comparison: ANN vs. ANN with Hyperparameter Tuning\n",
    "\n",
    "### 1. **ANN Model (Without Hyperparameter Tuning)**\n",
    "- **Accuracy**: 97.37%\n",
    "- **Precision (Class 0)**: 0.98 | **Recall (Class 0)**: 0.95 | **F1-score (Class 0)**: 0.96\n",
    "- **Precision (Class 1)**: 0.97 | **Recall (Class 1)**: 0.99 | **F1-score (Class 1)**: 0.98\n",
    "- This model provides high accuracy and excellent performance in both precision and recall, especially for Class 1.\n",
    "\n",
    "### 2. **ANN Model (With Hyperparameter Tuning)**\n",
    "- **Accuracy**: 96.49%\n",
    "- **Precision (Class 0)**: 0.93 | **Recall (Class 0)**: 0.98 | **F1-score (Class 0)**: 0.95\n",
    "- **Precision (Class 1)**: 0.99 | **Recall (Class 1)**: 0.96 | **F1-score (Class 1)**: 0.97\n",
    "- The tuned model shows a slightly lower accuracy, but still achieves strong performance in both classes. Hyperparameter tuning improved the recall for Class 0, but at the cost of slight accuracy reduction.\n",
    "\n",
    "### **Conclusion:**\n",
    "- The **ANN Model (Without Hyperparameter Tuning)** performs better overall with a higher accuracy (97.37% vs. 96.49%).\n",
    "- Although the tuned model shows improvements in some metrics, the untuned model is the more effective choice for this dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKQukjPikx-R"
   },
   "source": [
    "## **Saving the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNsDscZXi2LI",
    "outputId": "2e286970-7e4d-4f3b-d92a-c68706c086da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and scaler have been saved as 'ann_model.joblib' and 'scaler.joblib' respectively.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Define the model and scaler to be saved\n",
    "model_to_save = ann  # Best model after training\n",
    "scaler_to_save = scaler  # Scaler used for preprocessing\n",
    "\n",
    "# Saving the model to a file\n",
    "model_filename = 'ann_model.joblib'\n",
    "scaler_filename = 'scaler.joblib'\n",
    "\n",
    "# Use joblib to save both the model and scaler\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    joblib.dump(model_to_save, model_file)\n",
    "\n",
    "with open(scaler_filename, 'wb') as scaler_file:\n",
    "    joblib.dump(scaler_to_save, scaler_file)\n",
    "\n",
    "print(f\"Model and scaler have been saved as '{model_filename}' and '{scaler_filename}' respectively.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Github Link :** https://github.com/Rutvik-06/Assignment-1-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cloud Deployment Link :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
